{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc230e8-6786-4b03-8fbf-01b2144c062d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_all_function_names(code):\n",
    "    \"\"\"\n",
    "    Extract all function names defined in a Python file.\n",
    "    \"\"\"\n",
    "    pattern = r\"def\\s+(\\w+)\\s*\\(\"\n",
    "    return re.findall(pattern, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f3f42c-38be-419c-b895-c15b1b2d0e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "PIPELINES_ROOT = \"/Workspace/Users/divakar.c@diggibyte.com/Demo_pipelines\"\n",
    "OUTPUT_DIR = \"/Workspace/Users/aakanksha.shrivas@diggibyte.com/DealShare-Project/Dealshare_Standard_Pipeline/Standard_Pipelines\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "METADATA_FILE_NAME = \"metadata.yaml\"\n",
    "\n",
    "# =========================\n",
    "# DEFAULT CELL (MANDATORY)\n",
    "# =========================\n",
    "DEFAULT_CODE = \"\"\"# Databricks notebook source\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "mage_ai_path = os.path.join(\n",
    "    notebook_dir,\n",
    "    '/Workspace/Users/aakanksha.shrivas@diggibyte.com/DealShare-Project/mage-ai'\n",
    ")\n",
    "\n",
    "print(f\"Adding to sys.path: {mage_ai_path}\")\n",
    "if mage_ai_path not in sys.path:\n",
    "    sys.path.insert(0, mage_ai_path)\n",
    "\n",
    "import mage_ai\n",
    "print(f\"Successfully imported mage_ai from: {mage_ai.__file__}\")\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# UTIL FUNCTIONS\n",
    "# -----------------------------\n",
    "def read_block_code(pipeline_dir, uuid):\n",
    "    file_path = os.path.join(pipeline_dir, f\"{uuid}.py\")\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Missing block file: {file_path}\")\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "\n",
    "def generate_notebook(pipeline_dir):\n",
    "    metadata_path = os.path.join(pipeline_dir, METADATA_FILE_NAME)\n",
    "\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = yaml.safe_load(f)\n",
    "\n",
    "    blocks = metadata[\"blocks\"]\n",
    "    pipeline_name = metadata.get(\"name\", os.path.basename(pipeline_dir))\n",
    "\n",
    "    # -----------------------------\n",
    "    # BUILD DAG\n",
    "    # -----------------------------\n",
    "    block_map = {b[\"uuid\"]: b for b in blocks}\n",
    "    graph = defaultdict(list)\n",
    "    in_degree = defaultdict(int)\n",
    "\n",
    "    for b in blocks:\n",
    "        for upstream in b.get(\"upstream_blocks\", []):\n",
    "            graph[upstream].append(b[\"uuid\"])\n",
    "            in_degree[b[\"uuid\"]] += 1\n",
    "\n",
    "    for b in block_map:\n",
    "        in_degree.setdefault(b, 0)\n",
    "\n",
    "    # -----------------------------\n",
    "    # TOPOLOGICAL SORT\n",
    "    # -----------------------------\n",
    "    queue = deque([b for b in in_degree if in_degree[b] == 0])\n",
    "    execution_order = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        execution_order.append(node)\n",
    "        for downstream in graph[node]:\n",
    "            in_degree[downstream] -= 1\n",
    "            if in_degree[downstream] == 0:\n",
    "                queue.append(downstream)\n",
    "\n",
    "    if len(execution_order) != len(block_map):\n",
    "        raise Exception(f\"Cycle detected in pipeline: {pipeline_name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # NOTEBOOK BUILD\n",
    "    # -----------------------------\n",
    "    lines = []\n",
    "\n",
    "    def add_cell(content):\n",
    "        lines.append(\"# COMMAND ----------\")\n",
    "        lines.append(content)\n",
    "        lines.append(\"\")\n",
    "\n",
    "    # Header\n",
    "    lines.append(\"# Databricks notebook source\")\n",
    "    lines.append(\"# AUTO-GENERATED FROM MAGE\")\n",
    "    lines.append(f\"# Pipeline: {pipeline_name}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "\n",
    "    # CELL 1: DEFAULT CODE\n",
    "    add_cell(DEFAULT_CODE.strip())\n",
    "\n",
    "    add_cell(f\"\"\"\n",
    "PIPELINE_NAME = \"{pipeline_name}\"\n",
    "print(f\"-----------Starting pipeline: {{PIPELINE_NAME}}-----------\")\n",
    "\"\"\".strip())\n",
    "\n",
    "    # Blocks\n",
    "    for block_id in execution_order:\n",
    "        block = block_map[block_id]\n",
    "        block_type = block[\"type\"]\n",
    "        upstream = block.get(\"upstream_blocks\", [])\n",
    "\n",
    "        code = read_block_code(pipeline_dir, block_id)\n",
    "\n",
    "        inputs = \", \".join(f\"{u}_out\" for u in upstream)\n",
    "        output_assignment = f\"{block_id}_out = \" if block_type != \"data_exporter\" else \"\"\n",
    "        \n",
    "        cell=f\"\"\"\n",
    "        # MAGIC %md\n",
    "        # MAGIC **Mage block:** {block_id}\n",
    "        # MAGIC **Type:** {block_type}\n",
    "        \"\"\".strip()\n",
    "\n",
    "        cell1 = f\"\"\"\n",
    "\n",
    "{code}\n",
    "\"\"\".strip()\n",
    "\n",
    "        # Function calls\n",
    "        functions = extract_all_function_names(code)\n",
    "        calls = \"\\n\".join(f\"{fn}\" for fn in functions)\n",
    "\n",
    "        cell2 = f\"\"\"\n",
    "        {output_assignment}{calls}({inputs})\n",
    "         \"\"\".strip()\n",
    "\n",
    "        add_cell(cell)\n",
    "        add_cell(cell1)\n",
    "        add_cell(cell2)\n",
    "\n",
    "\n",
    "    # Footer\n",
    "    add_cell(\"\"\"\n",
    "print(f\"-----------Pipeline {PIPELINE_NAME} completed successfully-----------\")\n",
    "\"\"\".strip())\n",
    "\n",
    "    # Write notebook\n",
    "    notebook_path = os.path.join(OUTPUT_DIR, f\"{pipeline_name}.py\")\n",
    "    with open(notebook_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"-----------Generated notebook: {notebook_path}-----------\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS ALL PIPELINES\n",
    "# -----------------------------\n",
    "for pipeline_folder in os.listdir(PIPELINES_ROOT):\n",
    "    pipeline_dir = os.path.join(PIPELINES_ROOT, pipeline_folder)\n",
    "\n",
    "    if not os.path.isdir(pipeline_dir):\n",
    "        continue\n",
    "\n",
    "    metadata_path = os.path.join(pipeline_dir, METADATA_FILE_NAME)\n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(f\"**************Skipping (no metadata.yaml): {pipeline_folder}**************\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        generate_notebook(pipeline_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"**************Failed pipeline {pipeline_folder}: {e}**************\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NB_Copy_from_Mage_to_Dbx",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
